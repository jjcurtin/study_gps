---
title: "Make Lapse Labels"
author: "Coco Yu & Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true 
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

## Code Status

Complete and up to current lab practices as of 09/2024.

## Notes

Cleaning criteria:

- Lapses longer than 24 hours were deemed unfeasible and were excluded
- Lapses of a negative duration were inverted, unless they were longer than
24 hours in which case they were excluded
- These labels were used to generate day-level models, therefore lapses which were
collected during interviews or otherwise had unreliable times were retained (e.g., we
trust that participants were accurate about the day they lapsed, even if retrospective
hours of lapse might not be accurate)

Special cases:

- `lapse_start` for subid 213 was manually changed from one recorded lapse of ~150 hours
to a week of successive lapses. The EMA identification label from this once instance of reporting
was retained for recordkeeping.
- subid 180 had a duplicate recording of lapse listed, which was deleted; this row showed one
sustained lapse as ~150 hours, but subject also individually reported lapsing each day in separate
interview. Therefore, the one sustained long lapse recording was deleted.

## Setup

### Set up environment
```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "a58e57da996d1b70bb9a5b58241325d6fd78890f")
```

### Paths
```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
path_gps <- format_path("studydata/risk/data_processed/gps")
```

### Packages and source
```{r}
library(tidyverse)
library(kableExtra, exclude = "group_rows")
library(lubridate)
library(janitor, include.only = c("tabyl", "clean_names"))
library(here, include.only = c("here"))

devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")

# adjust plot visuals
theme_set(theme_classic())
options(tibble.width = Inf, dplyr.print_max = Inf)
```

## Read in data

Read in study_dates file specific to study_gps (lists start and end of data).
```{r}
study_dates <- read_csv(here(path_gps, "study_dates.csv"),
                        col_types = cols(subid = "d", study_start = "c", 
                                         study_end = "c")) |> 
  mutate(study_start = as_datetime(study_start, tz = "America/Chicago"),
         study_end = as_datetime(study_end, tz = "America/Chicago")) |> 
  select(subid, study_start, study_end) |>
  glimpse()
```

Read in lapses_day file (lists day, time, duration of lapse).
```{r}
lapses <- read_csv(here(path_shared, "lapses_day.csv"),
                   col_types = cols(subid = "d", exclude = "c",
                                    lapse_start_date = "c", 
                                    lapse_start_time = "c",
                                    lapse_end_date = "c",
                                    lapse_end_time = "c")) |> 
  mutate(lapse_start = as_datetime(lapse_start, tz = "America/Chicago")) |> 
  glimpse()
```

Pulling from `study_dates`, generate a list of all consecutive days on study for which we will
need to make a lapse prediction. This will be all of the dates on study listed in study_dates,
excluding the first and last days on study (assuming incomplete data on first and last day of
participation).

> CP 9/3: We might want to circle back to this. For subjects who had their data truncated, we might
be able to predict on their last day, too. Is that meaningful?

```{r}
labels <- study_dates |> 
  rowwise() |>
  mutate(day_start = list(seq.POSIXt(study_start + days(1), study_end - days(1), by = "day"))) |> 
  unnest(day_start) |>
  mutate(day_start = update(day_start, hour = 4, minute = 0)) |> 
  select(subid, day_start) |> 
  glimpse()

# use to check to make sure individual labels look accurate for subs w filtered dates
# labels |> filter(subid == 30) |> filter(row_number()==1 | row_number()==n())
```

If `lapse_start_time` is NA, `lapse_start` will be NA (even if `lapse_start_date` exists).
This chunk fills in missing values with proxy end dates and times and sets all to
America/Chicago time zone.
```{r}
lapses <- lapses |> 
  mutate(
    lapse_end_date = if_else(is.na(lapse_end_date),
                             format(mdy(lapse_start_date) + days(1), "%m/%d/%Y"),
                             lapse_end_date),
    lapse_start_time = if_else(is.na(lapse_start_time), "20:00", lapse_start_time),
    lapse_end_time = if_else(is.na(lapse_end_time), "2:00", lapse_end_time),
    lapse_start = mdy_hm(paste(lapse_start_date, lapse_start_time)),
    lapse_start = force_tz(lapse_start, tzone = ema_1_6),
    lapse_start = as_datetime(lapse_start, tz = "America/Chicago"),
    lapse_end = mdy_hm(paste(lapse_end_date, lapse_end_time)),
    lapse_end = force_tz(lapse_end, tzone = ema_1_6),
    lapse_end = as_datetime(lapse_end, tz = "America/Chicago")
    ) |> 
  glimpse()

any(is.na(lapses$lapse_start))
any(is.na(lapses$lapse_end))
```

Merge lapses and labels dataframe.
```{r}
# initiate blank lapse column
labels <- labels |> 
  mutate(day_end = day_start + days(1) - seconds(1),
         lapse = NA)

lapses_valid <- lapses |> 
  filter(exclude == "FALSE") |> 
  filter(!is.na(lapse_start))

for (i in 1:nrow(lapses_valid)){
  labels <- labels |> 
    mutate(lapse = if_else(subid == lapses_valid$subid[i] &
                             day_start <= lapses_valid$lapse_start[i] &
                             day_end >= lapses_valid$lapse_start[i],
                           "lapse", lapse))
}

lapses_exclude <- lapses |> 
  filter(exclude == "TRUE") |> 
  filter(!is.na(lapse_start))

for (i in 1:nrow(lapses_exclude)){
  labels <- labels |> 
    mutate(lapse = if_else(subid == lapses_exclude$subid[i] &
                             day_start <= lapses_exclude$lapse_start[i] &
                             day_end >= lapses_exclude$lapse_start[i],
                           "exclude", lapse),
           lapse = if_else(subid == lapses_exclude$subid[i] &
                             day_start <= lapses_exclude$lapse_end[i] &
                             day_end >= lapses_exclude$lapse_end[i],
                           "exclude", lapse))
}

labels <- labels |> 
  mutate(lapse = if_else(is.na(lapse), "no lapse", lapse)) |> 
  filter(lapse != "exclude")
```

## EDA

Count number of unique subids.
```{r}
(length(unique(labels$subid)))
```

Percentage of lapse versus no lapse days.
```{r}
labels |> 
  tabyl(lapse)
```

Number of lapses by subid.
```{r}
labels |> 
  tabyl(subid, lapse)
```

lapse % and number by participant (histogram)
```{r}
labels |>
  group_by(subid) |>
  filter(lapse == "lapse") |> 
  mutate(lapse, n = n()) |>
  pull(n) |> 
  hist(breaks = 30)
```

```{r}
labels |>
  group_by(subid) |> 
  mutate(total = n(),
         positive = count(lapse == "lapse")) |>
  head()
  hist()
```

## Write-out csv

```{r}
labels |> 
  write_csv(here(path_gps, "labels.csv")) |> 
  glimpse()
```
---
title: "Get weather data"
author: "Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Housekeeping

## Code Status

Complete as of 05/2025.

## Notes

This script pulls weather data using the ACIS RCC query builder.

Acronyms:

 - ACIS = Applied Climate Information System
 - RCC = Regional Climate Center, part of NOAA
 - NOAA = National Oceanic and Atmospheric Administration
 - WBAN = Weather Bureau Army Navy identifier, five digit numeric code that identifies a weather station
 - ICAO =  International Civil Aviation Organization identifier, four digit alphanumeric identifier that identifies a weather station
 
Links:

 - Information on weather station code abbreviations: https://mrcc.purdue.edu/CLIMATE/stnchooserIdDescrip.jsp
 - Documentation for RCC ACIS: https://www.rcc-acis.org/docs_webservices.html
 - RCC ACIS query builder: https://builder.rcc-acis.org/

Units of measurement:

 - All temperatures are denoted *by default* in Fahrenheit
 - Snow, snow depth, and precipitation are all denoted *by default* in inches

# Set up

## Set up environment

```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "de12d764438078a9341db9bc0b2472c87e0ae846")
```

## Paths

```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
```

## Packages and source

```{r}
#| message: false
#| warning: false
#| echo: false

# for data wrangling
library(tidyverse)
library(janitor, exclude = c("chisq.test", 
                             "fisher.test"))
library(lubridate)
library(future)

source(here::here("../lab_support/fun_gps.R"))
```

## Load in data

```{r}
gps <- read_csv(here::here(path_shared, "gps_enriched.csv.xz"), 
                 show_col_types = FALSE) |>
    mutate(time = with_tz(time, tz = "America/Chicago"),
           dist = dist / 1609.344,
           duration = duration / 60,
           speed = dist / duration,
           dist_context = dist_context / 1609.344) |> 
  mutate(duration = if_else(dist > 0.01 & duration == 0, NA_real_,
                            duration),
         duration = if_else(speed > 100, NA_real_,
                            duration),
         duration = if_else(duration > .5 & dist > 0.31, NA_real_,
                            duration),
         known_loc = if_else(dist_context <= 0.031 & speed <= 4,
                             TRUE, FALSE),
         known_loc = if_else(is.na(known_loc), FALSE, known_loc))
```

# Prepare data for weather pulling

Create a day-level identifier for subjects. This will enable us to apply this filter at the day level.
```{r}
gps <- gps |>
  group_by(subid, date) |> 
  mutate(day_label = cur_group_id()) |> 
  ungroup()

gps |> 
  select(subid, lat, lon, time, day_label) |>
  distinct(subid, .keep_all = TRUE) |> 
  head()
```

Round lat/lon points to 4th decimal place per: https://blis.com/precision-matters-critical-importance-decimal-places-five-lowest-go/#:~:text=The%20number%20of%20decimal%20places%20correlates%20directly%20to%20the%20level,a%20large%20city%20or%20district.
```{r}
gps <- gps |>
  mutate(lat_rounded = round(lat, 4),
         lon_rounded = round(lon, 4))
```

Calculate lat/lon where individual spent the most time on a given day. If multiple maximum duration points, pull first from list.
```{r}
get_long_dur <- function(day_label_arg, gps) {

  context_tmp <- gps |> filter(day_label_arg == day_label)

  context_tmp <- context_tmp |>
    mutate(latlon = str_c(lat_rounded, ", ",lon_rounded))

  longest <- context_tmp |> 
    group_by(latlon) |> 
    summarize(duration = sum(duration), .groups = "drop") |> 
    slice_max(order_by = duration, n = 1) |> 
    slice_head(n = 1) # handles multiple maximums by taking the first 
  
  context_tmp <- context_tmp |> 
    filter(latlon == longest$latlon)

  return(context_tmp)
}
```

```{r}
gps_longest <- gps$day_label |>
  unique() |>
  furrr::future_map(\(day_label) get_long_dur(day_label_arg = day_label,
                                                gps)) |>
  list_rbind() |> 
  distinct(day_label, .keep_all = TRUE)

gps_longest |> 
  select(subid, lat, lon, time, day_label) |>
  distinct(subid, .keep_all = TRUE) |> 
  head()
```

# Get weather

Retrieve database of existing weather stations.
```{r}
first_date <- gps_longest |> arrange(date) |> mutate(first_date = first(date)) |> pull(first_date) |> unique()

last_date <- gps_longest |> arrange(date) |> mutate(last_date = last(date)) |> pull(last_date) |> unique()

weather_stns <- rbind(FluMoDL::NOAA_countryStations(fips = "US",
                                                    from = first_date - 1, to = last_date + 1),
                      FluMoDL::NOAA_countryStations(fips = "MX",
                                                    from = first_date - 1, to = last_date + 1))

weather_stns |> head()
```

All WBANs should be five digits. If a WBAN is not five digits, we should append one or two 0s to the beginning of the WBAN. We also need to ensure that blank rows in the ICAO column are set to NA for later filtering purposes.
```{r}
weather_stns <- weather_stns |> 
  mutate(wban = ifelse(nchar(wban) == 3, paste0(00, wban), wban),
         wban = ifelse(nchar(wban) == 4, paste0(0, wban), wban),
         icao = na_if(icao, ""))
```

Define function to identify the five closest weather stations. This function makes queries using WBAN numbers and ICAO identifiers. Prior to filtering, remove stations which do not have a valid WBAN or ICAO (might be buoys, etc.).
```{r}
identify_stn <- function(gps_arg, stn_arg, day_label_arg) {
  library(geosphere)
  gps_tmp <- gps_arg |> filter(day_label == day_label_arg)

  # pre-filter stations that have either a valid WBAN or ICAO
  valid_stn <- stn_arg[!(stn_arg$wban == 99999 & is.na(stn_arg$icao)), ]

  # create a distance matrix between GPS points and valid stations
  dist_matrix <- matrix(nrow = nrow(gps_tmp), ncol = nrow(valid_stn))
  for (i in 1:nrow(gps_tmp)) {
    for (j in 1:nrow(valid_stn)) {
      dist_matrix[i, j] <- distGeo(
        c(gps_tmp$lon[i], gps_tmp$lat[i]),
        c(valid_stn$lon[j], valid_stn$lat[j])
      )
    }
  }
  
  closest <- dist_matrix |> 
    as_tibble() |>
    pivot_longer(cols = everything(), names_to = "station_index", values_to = "distance") |>
    mutate(station_index = as.integer(gsub("V", "", station_index))) |> 
    slice_min(n = 5, order_by = distance) |> 
    mutate(subid = gps_tmp$subid,
           day_label = day_label_arg,
           date = gps_tmp$date,
           wban = valid_stn$wban[station_index],
           icao = valid_stn$icao[station_index],
           distance = distance / 1609.344) # convert to miles

  return(closest)
}

```

Match each longest duration lat/lon to closest weather station. Running this without the filter demonstrates that the majority of stations are within 50 miles, so set a distance threshold of 50.
```{r}
match_stns <- gps_longest$day_label |>
  unique() |>
  furrr::future_map(\(day_label) identify_stn(day_label_arg = day_label,
                                               stn_arg = weather_stns,
                                               gps_arg = gps_longest)) |>
  purrr::map_dfr(~ data.frame(subid = .x$subid, day_label = .x$day_label, wban = .x$wban,
                              icao = .x$icao, distance = .x$distance, date = .x$date)) |>
  filter(distance < 50) |> 
  mutate(obs_label = 1:n())

match_stns |> 
  distinct(subid, .keep_all = TRUE) |> 
  head()
```

Explore distances.
```{r}
match_stns |> 
  pull(distance) |> 
  skimr::skim()

match_stns |>
  pull(distance) |>
  hist()
```

Create a function which queries RCC ACIS for each date and weather station.
```{r}
pull_weather <- function(obs_label_arg, stn_arg) {
  
  stn_tmp <- stn_arg |> filter(obs_label == obs_label_arg)
  
  subid <- stn_tmp$subid
  wban <- stn_tmp$wban
  icao <- stn_tmp$icao
  query_date <- stn_tmp$date
  
  # Try WBAN first
  tryCatch({
    api_url <- paste0(
      'https://data.rcc-acis.org/StnData',
      '?sid=', wban, 
      '&date=', query_date, 
      '&elems=avgt,mint,maxt,snow,snwd,pcpn',
      '&output=csv'
    )
    
    temp_data <- read.csv(url(api_url), header = FALSE, skip = 1,
                        colClasses = c("V2" = "character", "V3" = "character", "V4" = "character",
                                       "V5" = "character", "V6" = "character", "V7" = "character"))
    
    # Check if the dataframe is empty
    if (nrow(temp_data) == 0) {
      message("Empty CSV for WBAN: ", wban, " on ", query_date)
      return(data.frame(date = as.Date(character()), 
                        avgt = character(),
                        mint = character(),
                        maxt = character(),
                        snow = character(),
                        snwd = character(),
                        pcpn = character(), 
                        wban = character(),
                        icao = character(),
                        subid = integer()))
    }
  
    # Process the data
    processed_data <- temp_data |> 
      rename("date" = "V1", "avgt" = "V2", "mint" = "V3", "maxt" = "V4",
             "snow" = "V5", "snwd" = "V6", "pcpn" = "V7") |> 
      mutate(date = as.Date(date),
             wban = wban,
             icao = icao,
             subid = subid)
    
    # Return the processed data
    return(processed_data)
  
  }, error = function(e) {
    message("Error fetching data for WBAN: ", wban, " on ", query_date, ". Trying ICAO...")
    
    # Try ICAO if WBAN fails
    tryCatch({
      api_url <- paste0(
        'https://data.rcc-acis.org/StnData',
        '?sid=', icao, 
        '&date=', query_date, 
        '&elems=avgt,mint,maxt,snow,snwd,pcpn',
        '&output=csv'
      )
      
      temp_data <- read.csv(url(api_url), header = FALSE, skip = 1,
                            colClasses = c("V2" = "character", "V3" = "character", "V4" = "character",
                                           "V5" = "character", "V6" = "character", "V7" = "character"))
      
      # Check if the data frame is empty
      if (nrow(temp_data) == 0) {
        message("Empty CSV for ICAO: ", icao, " on ", query_date)
        return(data.frame(date = as.Date(character()), 
                          avgt = character(),
                          mint = character(),
                          maxt = character(),
                          snow = character(),
                          snwd = character(),
                          pcpn = character(), 
                          wban = integer(),
                          icao = character(),
                          subid = integer()))
      }
      
      # Process the data
      processed_data <- temp_data |> 
        rename("date" = "V1", "avgt" = "V2", "mint" = "V3", "maxt" = "V4",
               "snow" = "V5", "snwd" = "V6", "pcpn" = "V7") |> 
        mutate(date = as.Date(date),
               wban = wban,
               icao = icao,
               subid = subid)
      
      return(processed_data)
      
    }, error = function(e) {
      message("Error fetching data for ICAO: ", icao, " on ", query_date)
      
      # If both fail, return a blank data frame
      return(data.frame(date = query_date, 
                        avgt = NA,
                        mint = NA,
                        maxt = NA,
                        snow = NA,
                        snwd = NA,
                        pcpn = NA, 
                        wban = wban,
                        icao = icao,
                        subid = subid))
      
      
    })
  })
  
}

```

Pull relevant weather data for a given subject on a given day. Missing data points are sometimes recorded as "M", so make sure to set these to be NA.
```{r, max.height='100px'}
weather <- match_stns$obs_label |>
  unique() |>
  furrr::future_map(\(obs_label) pull_weather(obs_label_arg = obs_label,
                                               stn_arg = match_stns)) |> 
  bind_rows() |>
  # missing datapoints are sometimes recorded as "M"
  mutate(across(where(is.character), ~na_if(., "M")))

weather |> 
  distinct(subid, .keep_all = TRUE) |> 
  head()
```

Create mean weather across rows. All "trace" values for precipitation, snow, and snow depth (denoted as "T") are set to .001 for purposes of averaging across rows. "Trace" represents values too small to be reliably measured.

> Could consider doing weighted means here, but most of the stations that end up getting pulled do not have data (likely buoys or other similar things).

```{r}
weather <- weather |> 
  group_by(subid, date) |>
  mutate(avgt = as.numeric(avgt),
         mint = as.numeric(mint),
         maxt = as.numeric(maxt),
         snow = if_else(snow == "T", ".001", snow),
         snwd = if_else(snwd == "T", ".001", snwd),
         pcpn = if_else(pcpn == "T", ".001", pcpn),
         snow = as.numeric(snow),
         snwd = as.numeric(snwd),
         pcpn = as.numeric(pcpn)) |> 
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
```

For how many points are we missing data?
```{r}
sum(is.na(weather$avgt))
```

What percentage of our total is that?
```{r}
missing <- sum(is.na(weather$avgt))
total <- nrow(weather)

missing/total
```

## Save out data for further feature engineering.
```{r}
weather |>
  write_csv(here::here(path_shared, "gps_weather.csv"))
```
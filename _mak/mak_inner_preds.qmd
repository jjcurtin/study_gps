---
title: "Fits and evaluates best model configs for `r params$study` study across `r params$model` models in inner loop of nested for `r params$window` window and `r params$version`"
author: "John Curtin & Kendra Wyant, updated by Claire Punturieri for GPS study"
date: "`r lubridate::today()`"
output: 
  html_document:
    toc: true 
    toc_depth: 4
format:
  html:
    embed-resources: true
params:
  study: "gps"
  window: "1day"
  version: "v6"
  cv: "nested_1_x_10_3_x_10"
  model: "main" 
editor_options: 
  chunk_output_type: console
---

### Code Status

Currently being updated for GPS study as of 10/2024.

### Notes
This script reads in CHTC performance metrics from the inner loops of CV, selects the best model configuration for each outer loop, trains those models and predicts into the inner folds.

Returns metrics, predictions (probabilities) and SHAPs

This script creates the following files in the `models` folder

* outer_metrics_*.rds
* outer_preds_*.rds
* outer_shaps_*.rds
* outer_shapsgrp_*.rds

where * = window_lead_version_cv


### To Do




### Set Up Environment

```{r}
study <- params$study
window <- params$window
version <- params$version
cv <- params$cv
model <- params$model
batch <- params$model
```

Function conflicts
```{r}
#| message: false
#| warning: false

# handle conflicts
options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")
tidymodels_conflictRules()
```

Packages for script
```{r}
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
library(probably)
```

Source support functions
```{r}
# EDA
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true")

# CHTC support functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true")
```

Absolute paths
```{r}
path_processed <- format_path(str_c("studydata/risk/data_processed/", study))
path_input <- format_path(str_c("studydata/risk/chtc/", study))
path_models <- format_path(str_c("studydata/risk/models/", study))
```

### Script Functions

Function to clean up poor choices for feature names for SHAPs!!
```{r}
clean_feature_names <- function(feat_name){
  new_name <- gsub(".l0", "", feat_name)
  new_name <- gsub("p6.rratesum_duration.", "p6.raw_duration.", new_name)
  new_name <- gsub("p12.rratesum_duration.", "p12.raw_duration.", new_name)
  new_name <- gsub("p24.rratesum_duration.", "p24.raw_duration.", new_name)
  new_name <- gsub("p48.rratesum_duration.", "p48.raw_duration.", new_name)
  new_name <- gsub("p72.rratesum_duration.", "p72.raw_duration.", new_name)
  new_name <- gsub("p168.rratesum_duration.", "p168.raw_duration.", new_name)
  new_name <- gsub("p6.dratesum_duration.", "p6.diff_duration.", new_name)
  new_name <- gsub("p12.dratesum_duration.", "p12.diff_duration.", new_name)
  new_name <- gsub("p24.dratesum_duration.", "p24.diff_duration.", new_name)
  new_name <- gsub("p48.dratesum_duration.", "p48.diff_duration.", new_name)
  new_name <- gsub("p72.dratesum_duration.", "p72.diff_duration.", new_name)
  new_name <- gsub("p168.dratesum_duration.", "p168.diff_duration.", new_name)
  new_name <- gsub("p6.rvar_location", "p6.raw_location_variance", new_name)
  new_name <- gsub("p12.rvar_location", "p12.raw_location_variance", new_name)
  new_name <- gsub("p24.rvar_location", "p24.raw_location_variance", new_name)
  new_name <- gsub("p48.rvar_location", "p48.raw_location_variance", new_name)
  new_name <- gsub("p72.rvar_location", "p72.raw_location_variance", new_name)
  new_name <- gsub("p168.rvar_location", "p168.raw_location_variance", new_name)
  new_name <- gsub("p6.dvar_location", "p6.diff_location_variance", new_name)
  new_name <- gsub("p12.dvar_location", "p12.diff_location_variance", new_name)
  new_name <- gsub("p24.dvar_location", "p24.diff_location_variance", new_name)
  new_name <- gsub("p48.dvar_location", "p48.diff_location_variance", new_name)
  new_name <- gsub("p72.dvar_location", "p72.diff_location_variance", new_name)
  new_name <- gsub("p168.dvar_location", "p168.diff_location_variance", new_name)
  return(new_name) 
}
```

Function to fit, predict, and calc metrics, preds, shaps
```{r}
fit_predict_eval <- function(outer_split_num, inner_split_num, splits, config_best){

  # write tmp file to repo to track progress through loop
  # delete this file when script is complete.  
  write_csv(tibble(stage = "eval",
                   outer_split_num = outer_split_num,
                   inner_split_num = inner_split_num,
                   start_time = Sys.time()),
            here::here(path_models, str_c("tmp_metrics_inner_progress_", window)),
            append = TRUE)
  
  d_in <- splits$inner_resamples[[outer_split_num]]$splits[[inner_split_num]] |>
    training() |> 
    select(-id_obs)  # not used for training; only needed in d_out to tag for later joins 
  
  d_out <- splits$inner_resamples[[outer_split_num]]$splits[[inner_split_num]] |>
    testing()
    
  rec <- build_recipe(d = d_in, config = config_best)
  rec_prepped <- rec |> 
    prep(training = d_in, strings_as_factors = FALSE)
  
  feat_in <- rec_prepped |> 
    bake(new_data = NULL)
  
  model_best <- fit_best_model(config_best, feat = feat_in, "classification")
  
  feat_out <- rec_prepped |> 
    bake(new_data = d_out)   # no id_obs because not included in d_in
  
  # metrics from raw (uncalibrated) predictions for held out fold
  preds_prob <- predict(model_best, feat_out,
                        type = "prob")
  # preds_class <- predict(model_best, feat_out, type = "class")$.pred_class

  # roc <- tibble(truth = feat_out$y, 
  #               prob = preds_prob[[str_c(".pred_", y_level_pos)]]) %>% 
  #     roc_auc(prob, truth = truth, event_level = "first") %>% 
  #     select(metric = .metric, 
  #            estimate = .estimate)
  
  # cm <- tibble(truth = feat_out$y, estimate = preds_class) %>% 
  #   conf_mat(truth, estimate)
  #   
  # metrics_out <- cm |> 
  #   summary(event_level = "first") |>   
  #   select(metric = .metric,
  #          estimate = .estimate) |> 
  #   filter(metric %in% c("sens", "spec", "ppv", "npv", "accuracy", "bal_accuracy")) |> 
  #   suppressWarnings() |>  # warning not about metrics we are returning
  #   bind_rows(roc) |> 
  #   pivot_wider(names_from = "metric", values_from = "estimate") |>    
  #   relocate(roc_auc, sens, spec, ppv, npv, accuracy, bal_accuracy) |> 
  #   bind_cols(config_best) |>
  #   relocate(outer_split_num, algorithm, feature_set, hp1, hp2, hp3, 
  #            resample) |> 
  #   relocate(accuracy_in, bal_accuracy_in, .after = last_col())

  # train calibration model train/test split on held in data
  # Skip for baseline models
  set.seed(2468)
  cal_split <- d_in |> 
    group_initial_split(group = all_of(cv_group), prop = 3/4)
  d_cal_in <- training(cal_split) 
  d_cal_out <- testing(cal_split)

  feat_cal_in <- rec |> 
    prep(training = d_cal_in, strings_as_factors = FALSE) |>  
    bake(new_data = NULL) 

  feat_cal_out <- rec |>  
    prep(training = d_cal_in, strings_as_factors = FALSE) |>  
    bake(new_data = d_cal_out) 

  model_cal <- fit_best_model(config_best, feat = feat_cal_in, "classification")

  # iso calibration
  iso <- predict(model_cal, feat_cal_out,
                 type = "prob") |> 
    mutate(truth = feat_cal_out$y) |> 
    cal_estimate_isotonic(truth = truth,
                          estimate = dplyr::starts_with(".pred_"))
  preds_prob_iso <- preds_prob |> 
    cal_apply(iso)

  # logistic calibration
  logi <- predict(model_cal, feat_cal_out,
                 type = "prob") |>
    mutate(truth = feat_cal_out$y) |>
    cal_estimate_logistic(truth = truth,
                           estimate = dplyr::starts_with(".pred_"),
                           smooth = TRUE)
  preds_prob_logi <- preds_prob |>
    cal_apply(logi)

  # beta calibration
  # beta <- predict(model_cal, feat_cal_out,
  #                 type = "prob") |>
  #   mutate(truth = feat_cal_out$y) |>
  #   cal_estimate_beta(truth = truth,
  #                     estimate = dplyr::starts_with(".pred_"),
  #                     smooth = TRUE)
  #preds_prob_beta <- preds_prob |>
    #cal_apply(beta)

  # combine raw and calibrated probs
  probs_out <- tibble(id_obs = d_out$id_obs,
                      outer_split_num = rep(outer_split_num, nrow(preds_prob)),
                      inner_split_num = rep(inner_split_num, nrow(preds_prob)),
                      prob_raw = preds_prob[[str_c(".pred_", y_level_pos)]],
                      prob_iso = preds_prob_iso[[str_c(".pred_", y_level_pos)]],
                      prob_logi = preds_prob_logi[[str_c(".pred_", y_level_pos)]],
                      #prob_beta = preds_prob_beta[[str_c(".pred_", y_level_pos)]],
                      label = d_out$y) 

  # SHAP in held out fold
  shaps_out <- SHAPforxgboost::shap.prep(xgb_model = extract_fit_engine(model_best),
                     X_train = feat_out |> select(-y) |>  as.matrix()) |>
   # add id_obs by multiple of number of features
    mutate(id_obs = rep(d_out$id_obs, times = ncol(feat_out) - 1),
           inner_split_num = inner_split_num, outer_split_num = outer_split_num) |> 
    relocate(id_obs, outer_split_num, inner_split_num)

  return(list(probs_out = probs_out,
              shaps_out = shaps_out))
}
```

### Read in aggregate CHTC metrics for inner folds
```{r}
config_best <- 
  read_csv(here::here(path_models, str_c("best_config_", version, "_", cv, "_", model, ".csv"))) |>
  slice(1) |> 
  select(algorithm, hp1, hp2, hp3, resample) |> 
    glimpse()
```



### Fit best model for each outer fold and get/save metrics, preds, SHAPs

Get data from ANY batch (all same) and make splits

ASSUMPTIONS: 

* Data are same for all batches
* format_data() is same for all batches
* Assumes full recipe is for all algorithms is present in all training controls with branches/ifs to select proper algorithm specific steps

Map over all outer splits to get predicted probabilities, metrics, and SHAPs from held out outer folds.  Then save predicted probs, metrics, and SHAPs

NOTE: Delete `outer_metrics_*` or this code chunk won't run!
```{r}
if(!file.exists(here::here(path_models, str_c("inner_preds_", 
                                  window, "_", version, "_", 
                                  cv, "_", model, ".rds")))){ 
  
  # can source any training control given assumptions above
  batch_names <- list.dirs(path_input, full.names = FALSE, recursive = FALSE)
  batch_names <- batch_names[str_detect(batch_names, "train") & 
                               str_detect(batch_names, cv) &
                               str_detect(batch_names, version)] #&
                               #str_detect(batch_names, window) &
                               #str_detect(batch_names, 
                                          #str_c(as.character(lead), "lag"))]
 
  batch_name <- batch_names[1] # can source any batch given assumptions above
  path_batch <- here::here(path_input, batch_name)
  source(here::here(path_batch, "input", "training_controls.R"))
  # NOTE: training controls overwrites path_batch but it matches   
                    
  chunks <- str_split_fixed(data_trn, "\\.", n = Inf) # parse name from extensions
  if (length(chunks) == 2) {
    fn <- str_c("data_trn.", chunks[[2]])
  } else {
    fn <- str_c("data_trn.", chunks[[2]], ".", chunks[[3]])
  }
    
  # open based on file type
  if (str_detect(fn, "csv")) {
    d <- read_csv(here::here(path_batch, "input", fn), show_col_types = FALSE) 
  } else {
    d <- read_rds(here::here(path_batch, "input", fn))
  }
  
  d <- format_data(d) |> 
    arrange(label_num) |>
    mutate(id_obs = 1:nrow(d))  # tmp add for linking obs
  
  splits <- d |> 
    make_splits(cv_resample_type, cv_resample, cv_outer_resample, 
                cv_inner_resample, cv_group, seed_splits)
  
  # generate separate inner and outer lists
  inner_split_num_list <- rep(1:10, times = 30)
  outer_split_num_list <- rep(1:30, each = 10)

  
  all <- map2(inner_split_num_list, outer_split_num_list, \(inner_split_nums, outer_split_nums)
       fit_predict_eval(inner_split_num = inner_split_nums, outer_split_num = outer_split_nums,
                        splits = splits, 
                        config_best = config_best))
  
  
  # # one option with mutate split_num column
  # all <- fit_predict_eval(split_num = 1, splits = splits, configs_best = configs_best)
  # 
  # 
  # all <- configs_best$split_num |> # or 1:300?
  #   map(\(split_num) fit_predict_eval(split_num = split_num, splits = splits, configs_best = configs_best))
  # 
  
  # original:
  #all <- configs_best$outer_split_num |> 
    #map(\(split_num) fit_predict_eval(split_num, splits, configs_best)) 
  
  
  rm(splits)  # save a bit of memory!
  
  write_csv(tibble(stage = "probs_save",
                   outer_split_num = NA, 
                   start_time = Sys.time()),
            here::here(path_models, str_c("tmp_metrics_inner_progress_",window)),
            append = TRUE)  
  probs_out <- all |> 
    map(\(l) pluck(l, "probs_out")) |> 
    list_rbind() |> 
    write_rds(here::here(path_models, str_c("inner_preds_", 
                                           window, "_", version, "_", 
                                           cv, "_", model, ".rds")))

  write_csv(tibble(stage = "shaps_save",
                 outer_split_num = NA, 
                 start_time = Sys.time()),
          here::here(path_models, str_c("tmp_metrics_inner_progress_", window)),
          append = TRUE)    
  shaps_out <- all |> 
    map(\(l) pluck(l, "shaps_out")) |>
    list_rbind() |> 
    # clean feature names;  See function above
    mutate(variable = fct_relabel(variable, clean_feature_names)) |> 
    # average SHAP metrics across repeats for same id_obs
    group_by(id_obs, variable) |> 
    summarize(value = mean(value), 
              # rfvalue is same across repeats but want included 
              rfvalue =  mean(rfvalue),  
              mean_value = mean(mean_value)) |> 
    write_rds(here::here(path_models, str_c("inner_shaps_", 
                                           window, "_", version, "_", 
                                           cv, "_", model, ".rds")))
} else {
  message("Resampled performance from nested CV previously calculated")
  shaps_out <- read_rds(here::here(path_models, str_c("inner_shaps_", 
                                                     window, "_", 
                                                     version, "_", 
                                                     cv, "_", model, ".rds")))
}
```

Now group SHAPs

- NOTE: Delete `outer_shapsgrp_*` or this code chunk won't run!
- NOTE: not run for baseline models

```{r}
if(!file.exists(here::here(path_models, str_c("inner_shapsgrp_septype3_",
                                            window, "_", version, "_",
                                            cv, ".rds"))) & model != "baseline"){

  message("Calculating grouped SHAPs")
  write_csv(tibble(stage = "shapsgrp_save",
                   outer_split_num = NA, 
                   start_time = Sys.time()),
            here::here(path_models, str_c("tmp_metrics_inner_progress_",window)),
            append = TRUE)
  
  shaps_out_grp <- shaps_out |> 
    # collapse across duration and raw + change
    mutate(variable_grp = if_else(str_detect(variable, ".risk"), "risky location", variable),
           #variable_grp = if_else(str_detect(variable_grp, ".type"), "type of location", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.aa"), "AA", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.airport"), "airport", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.bar"), "bar", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.cafe"), "cafe", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.church"), "church", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.communityspacerecreation"), "community space/recreation", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.errands"), "errands", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.family"), "home of family member", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.fitness"), "gym or other fitness location", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.friend"), "home of friend", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.healthcare"), "healthcare", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.home"), "home", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.library"), "library", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.liquorstore"), "liquor store", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.other"), "other unspecified location", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.park"), "park", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.publicdrinkingspace"), "public drinking space", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.restaurant"), "restaurant", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.school"), "school", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.temporaryresidence"), "temporary residence", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.travelstop"), "stop while traveling", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.volunteer"), "volunteering activity", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".type.work"), "work", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".alcohol"), "alcohol availability at location", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".avoid"), "location to avoid in recovery", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".emotion"), "location valence", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".drank"), "previous drinking location", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, "variance"), "location variance", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".transit"), "transitory movement", variable_grp),
           variable_grp = if_else(str_detect(variable_grp, ".evening"), "out of home in evening", variable_grp),
           ) |> 
    mutate(variable_grp = factor(variable_grp)) |>  
    group_by(id_obs, variable_grp) |>  # values are already averaged across repeats
    summarize(value = sum(value))
  
  shaps_out_grp |>  write_rds(here::here(path_models, 
                                          str_c("inner_shapsgrp_septype_", window, "_", 
                                                version, "_",
                                                cv, "_", model, ".rds")))
}
```


```{r}
# delete tracking file
if(file.exists(here::here(path_models, str_c("tmp_metrics_inner_progress_", window)))) {
  file.remove(here::here(path_models, str_c("tmp_metrics_inner_progress_", window)))
}
```

IMPORTANT:  We still need to select ONE final best config using the inner resampling approach AND then we need to fit that best config to ALL the data.

---
title: "Make enriched gps/location"
author: "John Curtin, updated by Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Housekeeping

## Code Status

Updated to current lab practices 07/2024.

## Notes   

This script aggregates GPS files for all subjects and then matches each 
geolocation to its nearest context.

The sample starts with the N = 151 participants who completed through at 
least follow-up 1 and who had valid lapse data.

We then did EDA (gps_eda.qmd) to confirm that GPS data are valid for these N=151.  
This resulted in further removals. Final sample is N = 146, with some subjects
having their data truncated to shorter periods of good data.

More details on these decisions are available in the cleaning of EMA and lapses
and in the mak_study_dates.qmd script.

# Create and clean enriched data

## Set up

### Set up environment
```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "a58e57da996d1b70bb9a5b58241325d6fd78890f")
```

### Paths
```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
path_gps <- format_path("studydata/risk/data_processed/gps")
```

### Packages and source
```{r}
#| message: false
#| warning: false

# for data wrangling
library(tidyverse)
library(lubridate)

source(here::here("../lab_support/fun_gps.R"))

# helpful lab functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true",
 sha1 = "c045eee2655a18dc85e715b78182f176327358a7"
)
```

### Initialize parallel processing
```{r}
cl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))
doParallel::registerDoParallel(cl)
```


## Data wrangling

### Study Dates

Open study dates b/c it contains all the subids with context and valid lapses and 
start and end dates for good GPS (determined iteratively in this script).

```{r}
study_dates <- read_csv(here::here(path_gps, "study_dates.csv"), col_types = "dTTT",
                     show_col_types = FALSE) |>  
  mutate(study_start = as_date(study_start),
         study_end = as_date(study_end))  |>  
  mutate(study_ndays = as.numeric(difftime(study_end, study_start, units = "days")))  |>  
  glimpse()
```

Extract subids from study_dates file.
```{r}
subids_dates <- study_dates |>  
  pull(subid) |>  
  unique()
```

### Locations (context)

Load in contextual information file.
```{r}
locs <- read_csv(here::here(path_shared, "locations.csv"), col_types = "cddcccccccccccdd",
              show_col_types = FALSE) |>  
  mutate(subid = as.numeric(subid)) |>  
  glimpse()
```

Extract subids from locations file.
```{r}
subids_locs <- locs |>  
  pull(subid) |>  
  unique()
```

Check if there are any subids missing location context.
```{r}
if(any(!(subids_dates %in% subids_locs))) stop("Missing location for some subids")
```

### GPS

Load in GPS data, only for verified subjects (those in study_dates file).
```{r}
gps <-  read_csv(here::here(path_shared, "gps.csv"),
              show_col_types = FALSE)  |>  
  filter(subid %in% subids_dates)  |>    # limit to sample in study_dates
  mutate(time = with_tz(time, tz = "America/Chicago")) |>  
  group_by(subid)  |>  
  mutate(date = date(time),
         dist = distGeo(as.matrix(tibble(lon, lat))),
         duration = difftime(lead(time), time, units = "mins"),
         duration = as.numeric(duration),
         duration = if_else(duration > 5 & dist > 500, NA_real_, duration)) |>  # set suspect gaps to NA if high duration AND moved
  ungroup()  |>  
  glimpse()
```

Create function to filter data based on study_dates. This is important for
subjects for whom we only want to use some of their data.

> 7/11 CP: this works yay! confirm with john before applying to dataset.

```{r}
date_filter <- function(gps, study_dates, id) {
  gps_filtered <- gps |> 
    filter(subid == id)
    
  study_dates_filtered <- study_dates |> 
    filter(subid == id)
    
  sd <- study_dates_filtered |> 
    pull(study_start) |> 
    as.Date()
    
  ed <- study_dates_filtered |> 
    pull(study_end) |> 
    as.Date()
    
  cleaned_data <- gps_filtered |> 
    filter(date >= sd)
  
  cleaned_data <- cleaned_data |> 
    filter(date <= ed)
    
  cleaned_data$subid <- id

  
  return(cleaned_data)
}
```

```{r}
# can see original dataset still includes data we want to exclude
gps |> filter(subid == 19) |> arrange(time) |> select(subid, time) |>
  filter(row_number() == 1 | row_number() == n())

# test out manual filtering
gps_mini <- gps |> filter(subid == 19)
study_dates_mini <- study_dates |> filter(subid == 19)

sd <- study_dates_mini |> pull(study_start)
ed <- study_dates_mini |> pull(study_end)

test <- gps_mini |> filter(date >= sd)
test <- test |> filter(date <= ed)

test |> arrange(time) |> select(subid, time) |> filter(row_number() == 1 | row_number() == n())

# function works with one subject
id <- c(19)
filtered_data <- date_filter(gps, study_dates, id)
```

```{r}
# try to map function
ids <- c(19, 265)

#tester <- map(\(ids) date_filter(gps, study_dates, id))
filtered_data <- map(ids, ~ date_filter(gps, study_dates, .x))
combined_data <- bind_rows(filtered_data)

combined_data |> filter(subid == 19) |> arrange(time) |> select(subid, time) |>
  filter(row_number() == 1 | row_number() == n())

combined_data |> filter(subid == 265) |> arrange(time) |> select(subid, time) |>
  filter(row_number() == 1 | row_number() == n())
```

Extract subids from GPS file.
```{r}
subids_gps <- gps |>  
  pull(subid)  |>  
  unique()  |>  
  print()
```

Check if there are any subids missing GPS.
```{r}
if(any(!(subids_dates %in% subids_gps))) stop("Missing gps for some subids")
```

### Merge context into GPS

Create function to enrich GPS with context for one subid
```{r}
enrich_subid <- function(a_subid, gps, locs) {
  gps <- gps |>  
    filter(subid == a_subid)
  
  locs <- locs |>  
    filter(subid == a_subid)
  
  enriched <- gps |>  
    bind_cols(map2_dfr(gps$lon, gps$lat, find_nearest_context, context = locs)) 
  
  return(enriched)
}
```

future_map over subids
```{r}
enriched <- subids_gps  |>
  map(\(subid) enrich_subid(subid, gps, locs)) |> 
  #furrr::future_map_dfr(enrich_subid, gps = gps, locs = locs)
  list_rbind() |>
  left_join(locs, by = c("subid", "context_id"))  |>  
  select(-lat.y, -lon.y, -data_type)  |>  
  rename(lat = lat.x, lon = lon.x)  |>  
  relocate(subid)
```


# Brief EDA

Glimpse enriched data.
```{r}
enriched  |>   
  glimpse()
```

Check length of subids (verify it is the same as above).
```{r}
enriched  |>  
  pull(subid) |>
  unique() |>  
  length()
```

Create table summarizing number of unique `context_id` observations per subject.
```{r}
enriched |>
  group_by(subid) |>
  summarise(unique.context = n_distinct(context_id)) |> 
  print_kbl()
```

Display unique `context_id` observations per subject in a histogram.
```{r}
enriched |>
  group_by(subid) |>
  summarise(unique.context = n_distinct(context_id)) |>
  pull(unique.context) |> 
  hist(col = "white", border = "black",
       xlab = "# of Unique Context IDs", ylab = "Frequency",
       main = "Histogram of Unique Context IDs per Subject")
```

Review of missing data for context. Can also look at cln_locations.qmd for further exploration. 
Omitting `vacation` here because we will likely not be using it.

- Type is missing for 110 for one location which accounts for all missing type in df
- Emotion missing for one entry of subids 3, 6, and 48
- Risk missing for an entry for subids 3, and 121.
```{r}
enriched[rowSums(is.na(enriched[, c("type", "drank", "alcohol", "emotion", "risk", "avoid")])) > 0, ] |>
  group_by(subid) |> 
  distinct(full_address, .keep_all = TRUE) |> 
  print_kbl()
```

Summary of `type` responses.
```{r}
enriched  |>  tab(type)
```

Summary of `drank` responses.
```{r}
enriched  |>  tab(drank)
```

Summary of `alcohol` responses.
```{r}
enriched  |>  tab(alcohol)
```

Summary of `emotion` responses.
```{r}
enriched  |>  tab(emotion)
```

Summary of `risk` responses.
```{r}
enriched  |>  tab(risk)
```

Summary of `avoid` responses.
```{r}
enriched  |>  tab(avoid)
```

# Save enriched GPS

Saving xz compressed for use on CHTC for feature engineering

```{r}
enriched  |>  
  write_csv(here::here(path_gps, "gps_enriched.csv.xz"), delim = ",")
```
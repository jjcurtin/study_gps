---
title: "Make enriched gps/location"
author: "John Curtin, updated by Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Housekeeping

## Code Status

In progress as of 07/2024.

## Notes

This script does EDA on the enriched GPS file, generated via mak_gps_enriched.qmd

# Set up

## Set up environment

```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "a58e57da996d1b70bb9a5b58241325d6fd78890f")
```

## Paths

```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
path_gps <- format_path("studydata/risk/data_processed/gps")
```

## Packages and source

```{r}
#| message: false
#| warning: false
#| echo: false

# for data wrangling
library(tidyverse)
library(janitor, exclude = c("chisq.test", 
                             "fisher.test"))
library(lubridate)
library(future)

source(here::here("../lab_support/fun_gps.R"))

# helpful lab functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true",
 sha1 = "c045eee2655a18dc85e715b78182f176327358a7"
)

# adjust plot visuals
theme_set(theme_classic())
options(tibble.width = Inf, dplyr.print_max = Inf)
```

## Initialize parallel processing

```{r}
cl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))
doParallel::registerDoParallel(cl)
plan(multisession, workers = parallel::detectCores(logical = FALSE))
```

## Load in data

Create function to filter data based on study_dates. This is important for subjects for whom we only want to use some of their data.

```{r}
date_filter <- function(id, gps, study_dates) {
  gps <- gps |> 
    filter(subid == id)
    
  study_dates <- study_dates |> 
    filter(subid == id)
    
  gps <- gps |> 
    filter(date >= study_dates$study_start) |> 
    filter(date <= study_dates$study_end)

  return(gps)
}
```

Create function to match GPS with context by subid.

```{r}
enrich_subid <- function(a_subid, gps, locs) {
  gps <- gps |>  
    filter(subid == a_subid)
  
  locs <- locs |>  
    filter(subid == a_subid)
  
  enriched <- gps |> 
    bind_cols(
      map2(gps$lon, gps$lat, 
           \(lon, lat) find_nearest_context(lon, lat, context = locs)) |> 
      bind_rows()
    )
  
  return(enriched)
}
```

Create place data file.

```{r}
if(file.exists(here::here(path_gps, "gps_enriched.csv.xz"))){

  message("Aggregate file already exist -- delete to recreate!")
  
  places <- read_csv(here::here(path_gps, "gps_enriched.csv.xz"), 
                 show_col_types = FALSE) |>
    mutate(time = with_tz(time, tz = "America/Chicago"))

} else{
  
  message("Merging raw GPS and context information...")
  
  message("...loading study_dates.csv")
  study_dates <- read_csv(here::here(path_gps, "study_dates.csv"),
                          show_col_types = FALSE) |>
    mutate(study_start = as_date(study_start),
           study_end = as_date(study_end))  |>
    mutate(study_ndays = as.numeric(difftime(study_end,
                                             study_start, units = "days")))
  
  subids_dates <- study_dates |>
    pull(subid) |>  
    unique()
  
  message("...loading locations.csv")
  locs <- read_csv(here::here(path_shared, "locations.csv"),
                   col_types = "cddcccccccccccdd",
                   show_col_types = FALSE) |>
    mutate(subid = as.numeric(subid)) |>
    filter(subid %in% subids_dates)
  
  message("...loading gps.csv")
  gps <-  read_csv(here::here(path_shared, "gps.csv"),
                   show_col_types = FALSE)  |>
    filter(subid %in% subids_dates)  |>    # limit to sample in study_dates
    mutate(time = with_tz(time, tz = "America/Chicago")) |>  
    group_by(subid)  |>  
    mutate(date = date(time),
           dist = distGeo(as.matrix(tibble(lon, lat))),
           duration = difftime(lead(time), time, units = "mins"),
           duration = as.numeric(duration)) |> 
    ungroup()
  
  message("...filtering GPS data to selected dates")
  gps <- subids_dates |>
    map(\(id) date_filter(id, gps, study_dates)) |> 
    bind_rows()
  
  subids_gps <- gps |>  
    pull(subid)  |>  
    unique()
  
  message("...creating place dataframe")
  places <- subids_gps  |>
      furrr::future_map_dfr(enrich_subid, gps = gps, locs = locs,
                        .options = furrr::furrr_options(seed = NULL)) |> 
    left_join(locs, by = c("subid", "context_id"))  |>
    select(-lat.y, -lon.y, -data_type) |>  
    rename(lat = lat.x, lon = lon.x) |>   
    relocate(subid)
  
}
```

# Filtering

## Overview

Glimpse places data.

```{r}
places |>
  glimpse()
```

Check length of subids (verify it is the same as above).

```{r}
places  |>  
  pull(subid) |>
  unique() |>  
  length()
```

Summarize number of unique `context_id` observations per subject.

```{r}
places |>
  group_by(subid) |>
  summarise(unique_context = n_distinct(context_id)) |> 
  print_kbl()

places |> 
  group_by(subid) |>
  summarise(unique_context = n_distinct(context_id)) |> 
  summarise(mean(unique_context), min(unique_context), max(unique_context))
```

Display unique `context_id` observations per subject in a histogram.

```{r}
png("hist1.png")
places |>
  group_by(subid) |>
  summarise(unique_context = n_distinct(context_id)) |>
  pull(unique_context) |> 
  hist(col = "white", border = "black",
       xlab = "# of Unique Context IDs", ylab = "Frequency",
       main = "Histogram of Unique Context IDs per Subject")
dev.off()
```

![Unique Context IDs](../hist1.png)

## Decisions

### One observation per day points

> Does distGeo calculate the distance with LEAD or LAG? Does this matter?

Define function to pull days with one GPS observation and the preceding and following row.

```{r}
single_obs <- function(places) {
  inds <- which(places$n_obs == 1)
  rows <- map(inds, function(x) (x-1):(x+1))
  places[unlist(rows),]
}
```

Count number of observations per day, then combined with enriched file.

```{r}
places_obs <- places |>
  group_by(subid, date) |>  
  summarise(n_obs = n())

places <- places_obs |> 
  right_join(places, by = c("subid", "date")) |> 
  ungroup()
```

Display number of 1-observation days.

```{r}
places |> filter(n_obs == 1) |> nrow()
```

Print table displaying 1-observation days, and preceding/subsequent rows.

```{r}
places |>
  single_obs() |>
  select(subid, time, n_obs, duration, dist) |>
  mutate(dist = dist / 1609.344) |>
  mutate(duration = duration / 60) |>
  print_kbl() |>
  kableExtra::scroll_box(width = "700px", height = "500px")
```

Print table displaying only 1-observation days, descending by **duration**. Suspicious if duration is LOW. Time differences calculated with LEAD (difference from NEXT row).

We can see here that all low duration timestamps are at the end of a day (compare `time` and `next_time`).

```{r}
places |>
  filter(n_obs == 1) |> 
  select(subid, time, n_obs, duration, dist) |>
  mutate(dist = dist / 1609.344,
         next_time = time + lubridate::minutes(as.integer(duration)),
         date_diff = date(next_time) - date(time),
         duration_hours = duration / 60) |>
  arrange(duration) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "700px", height = "500px")
```

Print table displaying only 1-observation days, descending by **distance**. Suspicious if distance is HIGH.

```{r}
places |>
  filter(n_obs == 1) |> 
  select(subid, date, n_obs, duration, dist) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60) |>
  arrange(desc(dist)) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "600px", height = "500px")
```

**FILTERING DECISION**

Filter out distances of more than 500 meters (0.31 miles). 500 meters selected for consistency with filtering out improbable jumps.

```{r}
places |> 
  filter(n_obs == 1) |>
  filter(dist > 500) |> 
  mutate(dist = dist / 1609.344,
         duration = duration / 60) |>
  nrow()
```

### Improbable jumps (next point far away)

Goal is to eliminate improbable jumps because that would suggest our calculations of total duration will not be accurate.

```{r}
png("scatter1.png")
places |>
  filter(!(n_obs == 1 & dist > 500)) |> 
  mutate(dist = dist / 1609.344,
         duration = duration / 60) |>
  # filter missing values for plot display
  filter(!(is.na(dist) | is.na(duration))) |> 
  ggplot(aes(x = dist, y = duration)) +
  scattermore::geom_scattermore(pointsize = 3, alpha = 0.3)
dev.off()
```

![Improbable Jumps](../scatter1.png)

**FILTERING DECISION**

Duration \> 5 minutes and distance \> 500 meters seems to work well because we want most points to cluster against axes (suggests someone is in one place or is moving).

```{r}
png("scatter2.png")
places |>
  filter(!(n_obs == 1 & dist > 500)) |> 
  # filter duration more than 5 minutes and a jump of more than 500 meters (0.31 miles)
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60) |>
  # filter missing values for plot display
  filter(!(is.na(dist) | is.na(duration))) |>
  ggplot(aes(x = dist, y = duration)) +
  scattermore::geom_scattermore(pointsize = 3, alpha = 0.3)
dev.off()
```

![Improbable Jumps - Post-Filter](../scatter2.png)

Check how many points we are losing.

```{r}
places |> 
  filter(duration > 5 & dist > 500) |> 
  nrow()
```

### Long time at point

#### Extended periods

Generate histogram displaying duration in hours.

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |>  # convert to hours
  pull(duration) |> 
  hist()
```

Check extended gaps, defined as lasting greater than 48 hours.

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |> 
  filter(duration > 48) |>
  pull(duration) |> 
  hist()
```

Count extended periods.

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |> 
  filter(duration > 48) |> 
  nrow()
```

Possible reasons for missing data could be tech issues or not leaving the house.

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |> 
  filter(duration > 48) |>
  select(subid, date, duration) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "600px", height = "500px")
```

Load in study_notes to cross reference.

```{r}
#notes <- read_csv("../analysis_risk/shared/notes/notes_raw.csv",
                  #show_col_types = FALSE)
```

Pull subids missing \> 48 hours of data and examine their notes.

Sedentary: - 3 broke leg, rarely left home - 26 had surgery and was housebound, rarely left home - 74 broke foot, rarely left home and worked close to home - 134 rarely left home - 139 rarely left home

All other subjects had reported tech issues or no specific notes.

```{r}
subids_gaps <- places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |> 
  filter(duration > 48) |>  
  pull(subid) |>  
  unique()

#notes |>  
   #filter(subid %in% subids_gaps) |> 
   #print_kbl() |> 
   #kableExtra::scroll_box(width = "700px", height = "500px")
```

**FILTERING DECISION**

Remove gaps for subjects with poor GPS quality. Subjects who were reportedly sedentary retain all gaps.

```{r}
sedentary <- c(3, 26, 74, 134, 139)

subids_gaps <- setdiff(subids_gaps, sedentary)

places |>
  mutate(duration = duration / 60) |>
  filter((subid %in% subids_gaps & duration > 48)) |> 
  nrow()
```

#### Duration greater than forced sampling time

> CP 8/6: Not so sure we should do anything with this other than look at it. Even though the forced sampling time for FollowMee was set to 2 hours, we know that the system was not perfect (especially if someone was in one place).

Examine points with duration longer than forced sampling time. The forced sampling time for FollowMee was 2 hours, unknown for Moves.

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |> 
  filter(duration > 2) |>
  select(subid, dist, duration) |> 
  arrange(desc(dist)) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

Examine long duration counts by app source (Moves or FollowMee).

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |> 
  filter(duration > 2) |>
  tab(app_source)
```

### Next points far away

Create histogram of `dist` with updated filtering.

```{r}
png("hist2.png")
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(duration = duration / 60,
         dist = dist / 1609.344) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |> 
  pull(dist) |> 
  hist()
dev.off()
```

![Distance Histogram](../hist2.png)

Visualize `dist` and `duration` scatterplot with current filtering.

```{r}
png("scatter3.png")
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |> 
  filter(!(is.na(dist) | is.na(duration))) |>
  ggplot(aes(x = dist, y = duration)) +
  scattermore::geom_scattermore(pointsize = 3)
dev.off()
```

![Distance Scatterplot](../scatter3.png)

These points suggest fast movement.

-   30 traveled to Cleveland, guessing high speed point is due to flight
-   207 traveled to Mexico, same reason as above appears to be apparent

**We will do more checks with respect to speed later on, so leave for now.**

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  # selected just for visualization
  filter((dist > 100)) |>
  select(subid, date, dist, duration) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "700px", height = "500px")
```

### Speed

#### Speed NaN

Speed is NaN if distance and duration are both equal to 0, or if distance and duration are NaN to begin with.

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(is.na(speed)) |>
  select(subid, dist, duration, speed) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "700px", height = "500px")

places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(is.na(speed)) |> 
  nrow()
```

Check points before dist and duration = 0 to see if lat and long are the same

```{r}
speed_nan <- function(places) {
  inds <- which(places$dist == 0 & places$duration == 0)
  rows <- map(inds, function(x) (x-1):(x+1))
  places[unlist(rows),]
}
```

These points appear to be the same. Therefore, we will remove these points.

```{r}
places |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  select(subid, lat, lon, dist, duration, speed) |> 
  speed_nan() |>
  # subset for easy loading
  head(300) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

**FILTERING DECISION**

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  nrow()
```

#### Speed Inf

Speed is infinite if there is a value for distance but no value for duration.

Duration of 0 could be due to a rounding error (perhaps duration of less than or around one minute?).

For the purpose of categorizing places, I don't think we need to do anything with these points.

```{r}
places |>
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |> 
  filter(is.infinite(speed)) |> 
  select(subid, dist, duration, speed) |>
  arrange(desc(dist)) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

Look at points before and after infinite points.

```{r}
speed_inf <- function(places) {
  inds <- which(is.infinite(places$speed))
  rows <- map(inds, function(x) (x-1):(x+1))
  places[unlist(rows),]
}
```

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  select(subid, lat, lon, dist, duration, speed) |> 
  speed_inf() |>
  # subset for easy loading
  head(300) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

**FILTERING DECISION**

Infinite rows appear to be duplicates, remove.

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(is.infinite(speed)) |>
  nrow()
```

#### Improbable speeds

Generate table of speeds over 100mph.

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter(speed > 100) |>
  select(subid, lat, lon, dist, duration, speed) |>
  arrange(desc(speed)) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

Look at row preceding and following 10000mph.

```{r}
speed_imp <- function(places) {
  inds <- which(places$speed > 10000)
  rows <- map(inds, function(x) (x-1):(x+1))
  places[unlist(rows),]
}
```

Notes from subject maps: - 94, 128 have bizarre banding - Plane travel: 30, 31, 44, 207, 243 - Long road trips (pinging between cell towers?): 40, 118, 221, 248

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  speed_imp() |> 
  select(subid, lat, lon, dist, duration, speed) |>
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

Histogram of all speed values.

```{r}
png("hist3.png")
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |> 
  pull(speed) |> 
  hist()
dev.off()
```

![Speed Histogram](../hist3.png)

Histogram of speed under 100mph.

```{r}
png("hist4.png")
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter(speed < 100) |> 
  pull(speed) |> 
  hist()
dev.off()
```

![Speed Histogram - Under 100mph](../hist4.png)

Count number of observations **under 100mph.**

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter(speed < 100) |> 
  nrow()
```

Count number of observations **above 100mph.**

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter(speed > 100) |> 
  nrow()
```

**FILTERING DECISION**

Remove all observations above 100mph (assuming this is at or around top car speed).

```{r}
places |> 
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter((speed > 100)) |> 
  nrow()
```

### Classifying stationary/transit behavior

```{r}
places_sub <- places |>
  # apply previous filtering
  filter(!(n_obs == 1 & dist > 500)) |>
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration,
         known_loc = if_else(dist_context <= 50, TRUE, FALSE)) |> 
         #track_type = if_else(speed <= 0.62, "stationary", "transit")) |>
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter(!(speed > 100)) |>
  # subset to only known locations
  filter(known_loc == 1) |>
  select(subid, sgmnt_type, duration, dist, speed, context_id) |>
  # https://health.gov/sites/default/files/2019-09/Physical_Activity_Guidelines_2nd_edition.pdf
  # ^ walking briskly/doing chores around house ~4mph upper limit
  mutate(cut = if_else(speed > 4, 1, 0),
         row_seq = sequence(rle(as.character(context_id))$lengths))
```

This shows us that the majority of the points classified as "transit" (above 4mph) do not fall in the "middle" of being at a location.

```{r}
first_seq_ids <- which(places_sub$row_seq == 1)
last_seq_ids <- first_seq_ids - 1
second_last_seq_ids <- first_seq_ids - 2

places_sub |>
    mutate(row_place = if_else(row_number() %in% first_seq_ids, "(1) first", "0"),
         row_place = if_else(row_number() %in% last_seq_ids, "(4) last", row_place),
         row_place = if_else(row_number() %in% second_last_seq_ids, "(3) second to last", row_place),
         row_place = if_else(row_place == "0", "(2) middle", row_place)) |> 
    tabyl(cut, row_place) |> 
    adorn_percentages("row") |> 
    adorn_pct_formatting((digits = 2)) |> 
    adorn_ns()
```

## Final filtering decisions

Compare nrow() before and after filtering to see how many points we lose.

```{r}
(places |> nrow()) - (places |>
                          filter(!(n_obs == 1 & dist > 500)) |>
                          filter(!(duration > 5 & dist > 500)) |>
                          mutate(dist = dist / 1609.344,
                                 duration = duration / 60,
                                 speed = dist / duration,
                                 known_loc = if_else(dist_context <= 50 & speed <= 4,
                                                     TRUE, FALSE)) |>
                          filter(!(subid %in% subids_gaps & duration > 48)) |>
                          filter(!(is.na(speed))) |>
                          filter(!(is.infinite(speed))) |>
                          filter(!(speed > 100)) |> 
                          nrow())
```

Apply final filter.

```{r}
# remove points or set to NA?
# duration = if_else(duration > 5 & dist > 500, NA_real_, duration))

places <- places |>
  # remove one observation days with high movement
  filter(!(n_obs == 1 & dist > 500)) |>
  # remove improbable jumps
  filter(!(duration > 5 & dist > 500)) |>
  mutate(dist = dist / 1609.344,
         duration = duration / 60,
         speed = dist / duration,
         known_loc = if_else(dist_context <= 50 & speed <= 4, TRUE, FALSE)) |> 
  filter(!(subid %in% subids_gaps & duration > 48)) |>
  filter(!(is.na(speed))) |>
  filter(!(is.infinite(speed))) |>
  filter(!(speed > 100))
```

# EDA

## Overview

Glimpse enriched data.

```{r}
places |>   
  glimpse()
```

Check length of subids (verify it is the same as above).

```{r}
places |>  
  pull(subid) |>
  unique() |>  
  length()
```

Create table summarizing number of unique `context_id` observations per subject.

```{r}
places |>
  group_by(subid) |>
  summarise(unique_context = n_distinct(context_id)) |> 
  print_kbl()

places |> 
  group_by(subid) |>
  summarise(unique_context = n_distinct(context_id)) |> 
  summarise(mean(unique_context), min(unique_context), max(unique_context))
```

Display unique `context_id` observations per subject in a histogram.

```{r}
png("hist5.png")
places |>
  group_by(subid) |>
  summarise(unique_context = n_distinct(context_id)) |>
  pull(unique_context) |> 
  hist(col = "white", border = "black",
       xlab = "# of Unique Context IDs", ylab = "Frequency",
       main = "Histogram of Unique Context IDs per Subject")
dev.off()
```

![Unique Context IDs - After Filtering](../hist5.png)

## Examine missing data

Total number of missing variables per column.

```{r}
colSums(is.na(places))
```

Review of missing data for context. Can also look at cln_locations.qmd for further exploration. Omitting `vacation` here because we will likely not be using it.

-   Type is missing for 110 for one location which accounts for all missing type in df
-   Emotion missing for one entry of subids 3, 6, and 48
-   Risk missing for an entry for subids 3, and 121.

```{r}
places[rowSums(is.na(places[, c("type", "drank", "alcohol", "emotion", "risk", "avoid")])) > 0, ] |>
  group_by(subid) |> 
  distinct(full_address, .keep_all = TRUE) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

## Summary by context

Summary of `type` responses.

```{r}
places |> tab(type)
```

```{r}
places |>
  group_by(subid) |>
  distinct(context_id, .keep_all = TRUE) |> 
  filter(type == "other") |>
  select(-sgmnt_type, -trckpnt_type, -app_source,
         -lat_context, -lon_context, -dist_context, -utc,
         -dist, -duration) |> 
  print_kbl() |> 
  kableExtra::scroll_box(width = "500px", height = "500px")
```

Summary of `drank` responses.

```{r}
places |> tab(drank)
```

Summary of `alcohol` responses.

```{r}
places |> tab(alcohol)
```

Summary of `emotion` responses.

```{r}
places |> tab(emotion)
```

Summary of `risk` responses.

```{r}
places |> tab(risk)
```

Summary of `avoid` responses.

```{r}
places |> tab(avoid)
```

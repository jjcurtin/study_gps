---
title: "Make enriched gps/location"
author: "John Curtin, updated by Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Housekeeping

## Code Status

Updated to current lab practices 07/2024.

## Notes   

This script aggregates GPS files for all subjects and then matches each 
geolocation to its nearest context.

The sample starts with the N = 151 participants who completed through at 
least follow-up 1 and who had valid lapse data.

We then did EDA (gps_eda.qmd) to confirm that GPS data are valid for these N=151.  
This resulted in further removals. Final sample is N = 146, with some subjects
having their data truncated to shorter periods of good data.

More details on these decisions are available in the cleaning of EMA and lapses
and in the mak_study_dates.qmd script.

# Create and clean enriched data

## Set up

### Set up environment
```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "a58e57da996d1b70bb9a5b58241325d6fd78890f")
```

### Paths
```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
path_gps <- format_path("studydata/risk/data_processed/gps")
path_cache <- format_path("studydata/risk/data_processed/gps/cache//")
```

### Packages and source
```{r}
#| message: false
#| warning: false

# for data wrangling
library(tidyverse)
library(lubridate)
library(tictoc)
library(xfun, include.only = "cache_rds")
library(future)

source(here::here("../lab_support/fun_gps.R"))

# helpful lab functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true",
 sha1 = "c045eee2655a18dc85e715b78182f176327358a7"
)
```

### Initialize parallel processing
```{r}
cl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))
doParallel::registerDoParallel(cl)
plan(multisession, workers = parallel::detectCores(logical = FALSE))
```


## Data wrangling

### Study Dates

Open study dates b/c it contains all the subids with context and valid lapses and 
start and end dates for good GPS (determined iteratively in this script).

```{r}
study_dates <- read_csv(here::here(path_gps, "study_dates.csv"),
                     show_col_types = FALSE) |>  
  mutate(study_start = as_date(study_start),
         study_end = as_date(study_end))  |>  
  mutate(study_ndays = as.numeric(difftime(study_end, 
                                           study_start, units = "days")))  |>  
  glimpse()
```

Extract subids from study_dates file.
```{r}
subids_dates <- study_dates |>  
  pull(subid) |>  
  unique()
```

### Locations (context)

Load in contextual information file.
```{r}
locs <- read_csv(here::here(path_shared, "locations.csv"), 
                 col_types = "cddcccccccccccdd",
                 show_col_types = FALSE) |>  
  mutate(subid = as.numeric(subid)) |>
  filter(subid %in% subids_dates)  |>    # limit to sample in study_dates
  glimpse()
```

Extract subids from locations file.
```{r}
subids_locs <- locs |>  
  pull(subid) |>  
  unique()
```

Check if there are any subids missing location context.
```{r}
if(any(!(subids_dates %in% subids_locs))) stop("Missing location for some subids")
```

### GPS

Load in GPS data, only for verified subjects (those in study_dates file).
```{r}
gps <-  read_csv(here::here(path_shared, "gps.csv"),
              show_col_types = FALSE)  |>  
  filter(subid %in% subids_dates)  |>    # limit to sample in study_dates
  mutate(time = with_tz(time, tz = "America/Chicago")) |>  
  group_by(subid)  |>  
  mutate(date = date(time),
         dist = distGeo(as.matrix(tibble(lon, lat))),
         duration = difftime(lead(time), time, units = "mins"),
         duration = as.numeric(duration),
         # set suspect gaps to NA if high duration AND moved
         duration = if_else(duration > 5 & dist > 500, NA_real_, duration)) |>  
  ungroup()  |>  
  glimpse()
```

Create function to filter data based on study_dates. This is important for
subjects for whom we only want to use some of their data.
```{r}
date_filter <- function(id, gps, study_dates) {
  gps <- gps |> 
    filter(subid == id)
    
  study_dates <- study_dates |> 
    filter(subid == id)
    
  gps <- gps |> 
    filter(date >= study_dates$study_start) |> 
    filter(date <= study_dates$study_end)

  return(gps)
}
```

Apply function to filter data based on study_dates.
```{r}
gps <- subids_dates |> 
  map(\(id) date_filter(id, gps, study_dates)) |> 
  bind_rows()
```

Extract subids from GPS file (should match subids_dates after filtering).
```{r}
subids_gps <- gps |>  
  pull(subid)  |>  
  unique()  |>  
  print()
```

Check if there are any subids missing GPS.
```{r}
if(any(!(subids_dates %in% subids_gps))) stop("Missing gps for some subids")
```

### Merge context into GPS

Create function to enrich GPS with context for one subid
```{r}
enrich_subid <- function(a_subid, gps, locs) {
  gps <- gps |>  
    filter(subid == a_subid)
    #select(lon, lat, dist, duration, time)
  
  #gps_measures <- gps |>
    #select(-lon, -lat) |> 
    #mutate(utc = with_tz(time, tzone = "UTC"))
  
  locs <- locs |>  
    filter(subid == a_subid)
  
  #enriched <- gps |>  
    #bind_cols(map2_dfr(gps$lon, gps$lat, find_nearest_context, context = locs)) 
  
  enriched <- gps |> 
    bind_cols(
      map2(gps$lon, gps$lat, 
           \(lon, lat) find_nearest_context(lon, lat, context = locs)) |> 
      bind_rows()
    )
  
  return(enriched)
}
```

```{r}
enriched <- subids_gps |> 
  furrr::future_map_dfr(enrich_subid, gps = gps, locs = locs) |> 
  left_join(locs, by = c("subid", "context_id")) |> 
  select(-lat.y, -lon.y, -data_type) |> 
  rename(lat = lat.x, lon = lon.x) |> 
  relocate(subid)
```


future_map over subids
```{r}
tic()
enriched <- cache_rds(expr = {
  subids_gps  |>
  furrr::future_map_dfr(enrich_subid, gps = gps, locs = locs,
                        .options = furrr::furrr_options(seed = NULL)) |> 
  left_join(locs, by = c("subid", "context_id"))  |>
  select(-lat_context, -lon_context)  |>  
  relocate(subid)
  },
  dir = (here::here(path_cache)),
  file = "enrich_all",
  rerun = FALSE
)
toc()

colSums(is.na(enriched))
```

Test over one subject

Seed set to null to suppress:

> Warning message:
UNRELIABLE VALUE: Future (‘<none>’) unexpectedly generated random numbers without specifying argument 'seed'. There is a risk that those random numbers are not statistically sound and the overall results might be invalid. To fix this, specify 'seed=TRUE'. This ensures that proper, parallel-safe random numbers are produced via the L'Ecuyer-CMRG method. To disable this check, use 'seed=NULL', or set option 'future.rng.onMisuse' to "ignore". 

```{r}
subid_test <- c(1)

tic()
enriched_test <- cache_rds(expr = {
  subid_test |> # subids_gps  |>
  furrr::future_map_dfr(enrich_subid, gps = gps, locs = locs,
                        # do we need to set a seed?
                        .options = furrr::furrr_options(seed = NULL)) |> 
  left_join(locs, by = c("subid", "context_id"))  |>
  select(-lat_context, -lon_context)  |>  
  relocate(subid)
  },
  dir = (here::here(path_cache)),
  file = "enrich_single",
  rerun = FALSE
)
toc()

colSums(is.na(enriched_test)) # why are there not more NA values?
```

# Save enriched GPS

Saving xz compressed for use on CHTC for feature engineering

```{r}
enriched  |>  
  write_csv(here::here(path_gps, "gps_enriched.csv.xz"))
```
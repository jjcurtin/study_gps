---
title: "Processed GPS EDA"
author: "Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Housekeeping

## Code Status

Complete to lab workflow standards as of 6/2024.

## Conclusions   

EDA is conducted here using subjects with credible lapse reporting and at least one month of data as defined in EMA paper. Five subjects are removed for lacking sufficient data and several subjects here have truncated data if their GPS signal was not consistent while on study. All of these decisions are tracked in and are generated using mak_study_dates.qmd

## Set up

## Environment
```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "a58e57da996d1b70bb9a5b58241325d6fd78890f")
```

### Paths
```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
path_gps <- format_path("studydata/risk/data_processed/gps")
path_maps <- format_path("studydata/risk/data_processed/gps/figures")
path_notes <- format_path("GitHub/analysis_risk/shared/notes")
```

## Packages and plot settings
```{r}
#| message: false
#| warning: false

library(tidyverse)
library(readxl)
library(geosphere)
library(lubridate)
library(XML)
library(kableExtra, exclude = c("group_rows"))
## static maps
library(ggmap)
register_stadiamaps("d4bd71d7-556a-4627-9515-ef6e96823ce3")

# load in helpful lab functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true",
  sha1 = "def6ce26ed7b2493931fde811adff9287ee8d874"
)
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true",
 sha1 = "c045eee2655a18dc85e715b78182f176327358a7"
)

# adjust plot visuals
theme_set(theme_classic())
options(tibble.width = Inf, dplyr.print_max = Inf)
```


## Examine individual participant data

### Load in data
```{r}
gps <- read_csv(here::here(path_shared, "gps.csv"), show_col_types = FALSE) |>
  relocate(subid)  |>
  mutate(time = with_tz(time, tzone = "America/Chicago")) |>
  mutate(date = date(time)) |> 
  glimpse()

# staff notes on subject gps quality
notes <- read_csv("../analysis_risk/shared/notes/notes_raw.csv",
                  show_col_types = FALSE)

# dates of screening, intake, and follow-up visits
study_dates <- read_csv(here::here(path_gps, "study_dates.csv"),
                        show_col_types = FALSE) |> 
  glimpse()
```

### Filter subjects with minimum amount of data

Pull list of subject IDs with at least one month data and credible lapse reporting.
```{r}
subids_dates <- study_dates |>  
  pull(subid) |>  
  unique()
```

Filter out subjects not included in study_dates.
```{r}
gps <-  gps |>  
  filter(subid %in% subids_dates)

gps |> pull(subid) |> unique() |> length()
```

### Count number of observations, including missing days

Count n_obs per day by subject -- this will only count days for which participants
have at least one data point.
```{r}
gps_obs <- gps |>
  group_by(subid, date) |>  
  summarise(n_obs = n())
```

Create data frame listing out all dates each subject was on study and should have
had data.
```{r}
dates_long <- study_dates |> 
  select(subid, study_start, study_end) |> 
  pivot_longer(cols = starts_with("study"), names_to = "point",
               values_to = "time") |>
  mutate(time = with_tz(time, tzone = "America/Chicago")) |>
  mutate(date = date(time)) |> 
  group_by(subid) |>
  complete(date = full_seq(date, 1), fill = list(dummy = 0)) |> 
  select(-time)
```

Merge with gps_obs. This will create "blank" days for days when subjects were on
study but no data points were collected, which we can then fill in with 0s.
```{r}
gps_obs <- dates_long |> 
  select(-point) |> 
  left_join(gps_obs, by = c("subid", "date")) |> 
  mutate(n_obs = if_else(is.na(n_obs), 0, n_obs))
```

### Number of observations per person

Calculate mean number of observations, median number of observations, number of
days on study, number of days with 0 observations (AKA missing days), and the
percentage of missing data -- all **per subject**.
```{r}
n_obs <- gps_obs |> 
  group_by(subid) |> 
  summarize(mean_nobs = mean(n_obs), median_nobs = median(n_obs), 
            n_days = n(), n_missing = sum(n_obs == 0), 
            per_missing = n_missing / n_days)
```

Display histogram of median # observations per subject.
```{r}
n_obs |>  
  ggplot(aes(x = median_nobs)) +
  geom_histogram(bins = 50, color = "black", fill = "white") +
  xlab("Median # of GPS observations")
```

Display histogram of mean # observations per subject.
```{r}
n_obs |>  
  ggplot(aes(x = mean_nobs)) +
  geom_histogram(bins = 50, color = "black", fill = "white") +
  xlab("Mean # of GPS observations")
```

Display histogram of percentage of missing observations per subject. Vertical red
line indicates missing 25% of data. All subjects with > 25% of missing data will
be individually examined.
```{r}
n_obs |>  
  ggplot(aes(x = per_missing)) +
  geom_histogram(bins = 50, color = "black", fill = "white") +
  annotate("rect", xmin = 0.25, xmax = 1.0, ymin = 0, ymax = Inf, alpha = 0.4, fill = "red") +
  xlab("% of missing GPS observations")
```

Table listing subjects with high missing data (above > 25%).
```{r}
n_obs |> 
  filter(per_missing > .25) |> 
  arrange(desc(per_missing)) |> 
  print_kbl() |> 
  scroll_box(width = "700px", height = "200px")
```

Create std_obs, a scaled version of n_obs based on total number of observations
and days on study per subject.
```{r}
std_obs <- gps_obs |>
  group_by(subid) |> 
  summarize(total_obs = sum(n_obs),
         total_days = n(),
         std_obs = total_obs/total_days)
```

Display histogram of # observations per subject on same scale.
```{r}
std_obs |>  
  ggplot(aes(x = std_obs)) +
  geom_histogram(bins = 10, color = "black", fill = "white") +
  xlab("# of GPS observations (scaled)")
```

### Number of observations per day

**Calculated with missing days included.**

Subset data frame to display average observations per day, SD, minimum observation, and maximum observation per subject.
```{r}
obs_per_day <- gps_obs |>
  group_by(subid) |>  
  summarise(avg_obs_per_day = mean(n_obs),
            sd = sd(n_obs),
            min = min(n_obs),
            max = max(n_obs)) 
```

Display minimum average observation per day and maximum average observation per day across subjects.
```{r}
min(obs_per_day$avg_obs_per_day)
max(obs_per_day$avg_obs_per_day)
```

Display minimum observations per day and maximum observations per day across subjects.
```{r}
min(obs_per_day$min)
max(obs_per_day$max)
```

Display average observations per day across all subjects (average of average observations per day).
```{r}
mean(obs_per_day$avg_obs_per_day)
```

Histogram of standard deviations (to look at high and low variance subjects).
```{r}
obs_per_day |>  
  ggplot(aes(x = sd)) +
  geom_histogram(bins = 10, color = "black", fill = "white") +
  xlab("Standard deviation of number of observations per day, by subject")
```

### Display number of observations by day per subject
```{r}
gps_obs |> 
  group_by(subid) |>
  print_kbl() |> 
  scroll_box(width = "700px", height = "200px")
```

### Examine longest consecutive period of data per subject.

Create function to count number of consecutive observations using rle() (run length encoding).
```{r}
gl <- function(x) {
  y <- c(0, unclass(diff(x))) # this part makes x into a vector
  r <- rle(y) # rle computes lengths of runs (sequences) in a vector
  max_length <- with(r, max(lengths[values == 1])) # pull out the longest consecutive period of data collection per subject
  
  # identify start and end dates
  if (length(max_length) > 0 && max_length > 0) {
    streaks <- which(r$lengths >= max_length & r$values == 1)
    start_index <- cumsum(r$lengths)[streaks][1] - r$lengths[streaks][1] + 1
    end_index <- cumsum(r$lengths)[streaks][1]
    start_date <- x[start_index]
    end_date <- x[end_index]
  } else {
    max_length <- 0
    start_date <- NA
    end_date <- NA
  }
  
  # list overall first and last dates on study
  first_recorded_date <- min(x)
  last_recorded_date <- max(x)
  
  # return maximum period of data collection and start and end dates
  data.frame(max_length = max_length,
             start_period = start_date,
             end_period = end_date,
             start_overall = first_recorded_date,
             end_overall = last_recorded_date)
}
```

Print table displaying longest number of days of data collection (for all subjects), including the start and end dates of those periods.

> CP note 7/8: the way I use this excludes 0s, so it might be overly conservative when counting periods? For example, someone could have a lot of good data but every ~10-15 days has a fluke 0 observation, which would make their max obs for a given period always be between ~10-15 even though they're nearly always providing data. Just something to keep in mind. Do we want no 0s, or do we tolerate some 0s?

```{r}
gps_obs |> 
  filter(n_obs > 0) |> 
  group_by(subid) |>
  # trying to mess around to see if I can get it to ignore 1 or 2 instances of repeated 0s
  #mutate(consecutive_zeros = cumsum(lag(n_obs == 0, default = FALSE) & n_obs == 0)) |> 
  #filter(consecutive_zeros <= 1) |> 
  summarise(max_streak = list(gl(date))) |> 
  unnest(cols = c(max_streak)) |> 
  arrange(max_length) |> 
  print_kbl()
```


### Plot number of observations by day per subject

Create timeseries plotting function, including mean n_obs of non-missing days.
```{r}
plot_timeseries <- function(x, y, z) {
    gps_obs <- gps_obs |> filter(subid == z)
    
    graph_title <- paste0("Subject ID", z, sep = " ")
  
    print(ggplot(data = gps_obs, aes(x = .data[[x]], y = .data[[y]], color = z)) +
          geom_line(color = "darkblue")) +
      labs(title = graph_title) +
      geom_hline(aes(yintercept = mean(n_obs[n_obs > 0]), color = "red"), linetype = 2, show.legend = FALSE) +
      # include option below to scale figures
      #coord_cartesian(ylim=c(0, 200))
      coord_cartesian(ylim=c(0, 500))
}
```

Get list of subjects.
```{r}
subid_all <- list(gps_obs$subid) |> unlist() |> unique()
```

If pdf output file does not already exist, create and save out plots in /data_processed/gps/figures.
```{r}
if(file.exists(here::here(path_maps, "per-subj-timeseries.pdf"))){

  message("PDF file already exist -- delete to recreate!")

} else{
  timeseries_plots <- subid_all |>
    map(\(subid) plot_timeseries("date", "n_obs", subid))
  
  output_file <- paste0(path_maps, "/per-subj-timeseries.pdf", sep = "")

  multi.page <- ggpubr::ggarrange(plotlist = timeseries_plots,
                                  nrow = 3, ncol = 1)
  ggpubr::ggexport(multi.page, filename = output_file)
}
```

### Create map plots for subjects with few obs per day

List subjects who have mean nobs below ~20.
```{r}
low_nobs_ids <- gps_obs |>
  mutate(mean_nobs = mean(n_obs[n_obs > 0])) |> 
  filter(mean_nobs < 20) |>
  select(subid) |>
  unlist() |> 
  unique()
```

Create function to generate static map per subject.
```{r}
plot_geo <- function(z) {
    gps <- gps |> filter(subid == z)
    
    graph_title <- paste0("Subject ID", z, sep = " ")
   
    cbbox <- make_bbox(lon = gps$lon, lat = gps$lat, f = .1)
    sq_map <- get_map(location = cbbox, maptype = "stamen_toner_lite")
    
    ggmap(sq_map) + 
      geom_point(data = gps, aes(x = gps$lon, y = gps$lat), 
                size = 1, lineend = "round", color="darkred") +
      labs(x = " ", y = " ", title = graph_title) +
      theme_minimal() +
      ggforce::facet_grid_paginate(~date, ncol = 2, nrow = 2, page = 10) +
      theme(legend.position = "none")
}
```

Generate individual GPS map per subject and save out in /shared/gps/figures if compiled file does already not exist.
```{r}
#| eval: false
#| label: Static subject maps

if(file.exists(here::here(path_gps, "per-subj-geo.pdf"))){

  message("PDF file already exist -- delete to recreate!")

} else{
  geo_plots <- low_nobs_ids |> 
    map(\(subid) plot_geo(subid))
  
  output_file <- paste0(path_gps, "/per-subj-geo.pdf", sep = "")

  multi.page <- ggpubr::ggarrange(plotlist = geo_plots,
                                    nrow = 1, ncol = 1)

  ggpubr::ggexport(multi.page, filename = output_file)
}
```

### Examine 1-observation days

Filter on days that have only one observation, sorting ascending on time to ensure that the individual points on these days are not all occurring around midnight (which would suggest spurious bursts of activity not actually related to the participant).
```{r}
full_join(gps, gps_obs, by=c("subid", "date")) |> 
  select(subid, lat, lon, time, n_obs) |> 
  filter(n_obs == 1) |>
  separate_wider_delim(time, delim = " ", names = c("date_tmp", "time")) |> 
  arrange(time) |>
  select(-date_tmp) |> 
  kable(caption = "1-observation days") |>
  kable_styling("striped") |> 
  scroll_box(width = "700px", height = "400px")
```
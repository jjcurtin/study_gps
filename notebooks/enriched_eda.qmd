---
title: "Make enriched gps/location"
author: "John Curtin, updated by Claire Punturieri"
date: "`r lubridate::today()`"
format: 
  html:
    toc: true
    toc_depth: 4
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# Housekeeping

## Code Status

Updated to current lab practices 07/2024.

## Notes   

This script aggregates GPS files for all subjects and then matches each 
geolocation to its nearest context.

The sample starts with the N = 151 participants who completed through at 
least follow-up 1 and who had valid lapse data.

We then did EDA (gps_eda.qmd) to confirm that GPS data are valid for these N=151.  
This resulted in further removals. Final sample is N = 146, with some subjects
having their data truncated to shorter periods of good data.

More details on these decisions are available in the cleaning of EMA and lapses
and in the mak_study_dates.qmd script.

# Create and clean enriched data

## Set up

### Set up environment
```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true", 
                      sha1 = "a58e57da996d1b70bb9a5b58241325d6fd78890f")
```

### Paths
```{r}
path_shared <- format_path("studydata/risk/data_processed/shared")
path_gps <- format_path("studydata/risk/data_processed/gps")
```

### Packages and source
```{r}
#| message: false
#| warning: false

# for data wrangling
library(tidyverse)
library(lubridate)

source(here::here("../lab_support/fun_gps.R"))

# helpful lab functions
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true",
 sha1 = "c045eee2655a18dc85e715b78182f176327358a7"
)
```

### Initialize parallel processing
```{r}
cl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))
doParallel::registerDoParallel(cl)
```

# Brief EDA

Glimpse enriched data.
```{r}
enriched  |>   
  glimpse()
```

Check length of subids (verify it is the same as above).
```{r}
enriched  |>  
  pull(subid) |>
  unique() |>  
  length()
```

Create table summarizing number of unique `context_id` observations per subject.
```{r}
enriched |>
  group_by(subid) |>
  summarise(unique.context = n_distinct(context_id)) |> 
  print_kbl()
```

Display unique `context_id` observations per subject in a histogram.
```{r}
enriched |>
  group_by(subid) |>
  summarise(unique.context = n_distinct(context_id)) |>
  pull(unique.context) |> 
  hist(col = "white", border = "black",
       xlab = "# of Unique Context IDs", ylab = "Frequency",
       main = "Histogram of Unique Context IDs per Subject")
```

Review of missing data for context. Can also look at cln_locations.qmd for further exploration. 
Omitting `vacation` here because we will likely not be using it.

- Type is missing for 110 for one location which accounts for all missing type in df
- Emotion missing for one entry of subids 3, 6, and 48
- Risk missing for an entry for subids 3, and 121.
```{r}
enriched[rowSums(is.na(enriched[, c("type", "drank", "alcohol", "emotion", "risk", "avoid")])) > 0, ] |>
  group_by(subid) |> 
  distinct(full_address, .keep_all = TRUE) |> 
  print_kbl()
```

Summary of `type` responses.
```{r}
enriched  |>  tab(type)
```

Summary of `drank` responses.
```{r}
enriched  |>  tab(drank)
```

Summary of `alcohol` responses.
```{r}
enriched  |>  tab(alcohol)
```

Summary of `emotion` responses.
```{r}
enriched  |>  tab(emotion)
```

Summary of `risk` responses.
```{r}
enriched  |>  tab(risk)
```

Summary of `avoid` responses.
```{r}
enriched  |>  tab(avoid)
```


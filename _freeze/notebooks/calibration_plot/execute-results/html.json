{
  "hash": "ddddb707633063e189b75764a6afdd03",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Validation set calibration\"\nauthor: \"John Curtin & Claire Punturieri\"\ndate: \"2024-10-22\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\nparams:\n  study: \"gps\"\n  version: \"v6\"\n  cv: \"nested_1_x_10_3_x_10\"\n  algorithms: \"xgboost\"   # \"all\" or name of specific algorithm\n  model: \"main\"\n  window: \"1day\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nstudy <- params$study\ncv <- params$cv\nmodel <- params$model\nalgorithms <- params$algorithms\nversion <- params$version\nwindow <- params$window\n```\n:::\n\n\nFunction conflicts\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\n# source\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"77e91675366f10788c6bcb59fa1cfc9ee0c75281\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\ntidymodels_conflictRules()\n```\n:::\n\n\nPackages for script\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(probably)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'probably'\n\nThe following objects are masked from 'package:base':\n\n    as.factor, as.ordered\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nlibrary(yardstick)\n```\n:::\n\n\nPath\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npath_models <- format_path(str_c(\"studydata/risk/models/\", study))\n```\n:::\n\n\n## Functions\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nget_brier <- function(split, df){\n  \n  #filter to split\n  probs_split <- df |> \n    filter(split_num == split)\n\n  raw <- probs_split |>\n    filter(method == \"prob_raw\") |> \n    brier_class(label, .pred_Lapse)\n  \n  logi <- probs_split |>\n    filter(method == \"prob_logi\") |> \n    brier_class(label, .pred_Lapse)\n  \n  iso <- probs_split |>\n    filter(method == \"prob_iso\") |> \n    brier_class(label, .pred_Lapse)\n  \n  #beta <- probs_split |>\n    #filter(method == \"prob_beta\") |> \n    #brier_class(label, .pred_Lapse)\n  \n  brier <- tibble(raw = raw$.estimate, \n                 logi = logi$.estimate, \n                 iso = iso$.estimate) \n  #               beta = beta$.estimate)\n  \n  #brier <- tibble(raw = raw$.estimate)\n  \n  return(brier)\n}\n```\n:::\n\n\n## Get Probs\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nprobs <- read_rds(here::here(path_models,\n                             str_c(\"inner_preds_\", window, \"_\", version, \"_\",\n                                         cv, \"_\", model, \".rds\"))) |>\n  mutate(split_num = 10 * outer_split_num + (inner_split_num - 10)) |> \n  pivot_longer(cols = starts_with(\"prob\"), \n               names_to = \"method\", \n               values_to = \".pred_Lapse\") |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 932,391\nColumns: 7\n$ id_obs          <int> 446, 446, 446, 447, 447, 447, 448, 448, 448, 449, 449,…\n$ outer_split_num <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ inner_split_num <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ label           <fct> no lapse, no lapse, no lapse, no lapse, no lapse, no l…\n$ split_num       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ method          <chr> \"prob_raw\", \"prob_iso\", \"prob_logi\", \"prob_raw\", \"prob…\n$ .pred_Lapse     <dbl> 0.32092649, 0.00000000, 0.08943453, 0.32092649, 0.0000…\n```\n\n\n:::\n:::\n\n\n\n## Brier Scores\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbrier <- 1:300 |>\n  map(\\(split_num) get_brier(split_num, probs)) |> \n  list_rbind()\n\nbrier |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n    raw   logi    iso\n  <dbl>  <dbl>  <dbl>\n1 0.182 0.0536 0.0503\n2 0.164 0.0175 0.0139\n3 0.238 0.0787 0.0758\n4 0.182 0.0727 0.0730\n5 0.203 0.0540 0.0436\n6 0.239 0.0978 0.0995\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nbrier |> summarize(across(everything(), list(mean, median)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  raw_1 raw_2 logi_1 logi_2  iso_1  iso_2\n  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 0.195 0.194 0.0684 0.0666 0.0680 0.0664\n```\n\n\n:::\n:::\n\n\n## Explore Plots\nRaw and logi\n\n::: {#cell-fig-calibration .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-calibration\n#| fig-cap: Comparison between raw (uncalibrated) and logistic (calibrated) probabilities. Predicted lapse probability represents the predicted probabilities derived from the model, whereas observed lapse rate reflects the true rate of lapses in the data. The dashed y = x line represents perfect performance, where predicted probabilities reflect true probabilities. Each point represents the midpoint of a given bin, which increase by 10% (i.e., 5% represents the midpoint from 0-10%).\n#| fig-height: 4\n#| fig-width: 6\ncols <- c(\"prob_raw\" = \"#FF9898FF\", \"prob_logi\" = \"#A91E45FF\")\n\nprobs |>\n  mutate(.pred_lapse = .pred_Lapse) |>\n  filter(method == \"prob_raw\" | method == \"prob_logi\") |> \n  cal_plot_breaks(truth = label, \n                  estimate = .pred_lapse,\n                  .by = method) +\n  scale_color_manual(values = cols,\n                     aesthetics = c(\"color\", \"fill\")) +\n  ylab(\"Observed Lapse Rate\") +\n  xlab(\"Predicted Lapse Probability (Bin Midpoint)\") +\n  facet_grid(~factor(method, levels=c('prob_raw','prob_logi'),\n                     labels = c(\"Raw (Uncalibrated) Probability\",\n                                \"Logistic (Calibrated) Probability\"))) +\n  scale_y_continuous(breaks = seq(0,1, by = .1),\n                     limits = seq(0,1)) +\n  scale_x_continuous(breaks = seq(0,1, by = .1),\n                     limits = seq(0,1)) +\n  theme_classic() +\n  theme(legend.position=\"none\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Comparison between raw (uncalibrated) and logistic (calibrated) probabilities. Predicted lapse probability represents the predicted probabilities derived from the model, whereas observed lapse rate reflects the true rate of lapses in the data. The dashed y = x line represents perfect performance, where predicted probabilities reflect true probabilities. Each point represents the midpoint of a given bin, which increase by 10% (i.e., 5% represents the midpoint from 0-10%).](calibration_plot_files/figure-html/fig-calibration-1.png){#fig-calibration width=576}\n:::\n:::",
    "supporting": [
      "calibration_plot_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}